seed: 0
device: None                              # Set to 'cpu' or 'cuda' to override automatic device selection

logging:
  log_dir: './experiments/fitting/logs'
  log_every_n_steps: 15
  visualize_every_n_steps: 120
  no_progress_bar: False

# Space and latents configuration
geometry:
  input_space: 'Position_Orientation'
  metric: # Rot(theta) @ diag(xi**2, xi**2 / epsilon**2, 1) @ Rot(theta)^T
    xi: 1.0
    epsilon: 1.0
  theta_range: 'zero'  # zero=[0, 2pi], shifted=[-pi, pi]
  group: 'SE-Perm' # Choises, 'SE', 'E', 'SE-Perm', 'E-Perm'
  dim_orientation: 2 # Choises, 0 to dim_signal
  triv: 'vanilla' # "vanilla", "expm", "cayley", "projection"
  latent_dim: 16
  num_latents: 4

# Solver configuration
solver:
  num_hidden: 64
  num_heads: 2
  embedding_type: rff-net                        # Choices, 'linear', 'rff', 'polynomial', 
  embedding_freq_multiplier_invariant: 0.05     # For SIREN this is the omega value, for RFF the 1/std and for polynomial the degree
  embedding_freq_multiplier_value: 0.01        # For SIREN this is the omega value, for RFF the 1/std and for polynomial the degree

# Eikonal equiation configurationßß
eikonal:
  factored: True
  power: 2
  hamiltonian: True

  ground_truth:
    active: True
    skip_r: 1
    skip_s: 5
    num_visualized: 2
    save_data: True
    force_recompute: False
    device: 'gpu'
    sub_riem: False
    n_max: 1e5
    n_max_initialisation: 1e4
    n_check: 2e3
    n_check_initialisation: 2e3
    tol: 1e-3
    initial_condition: 200.0

# Data configuration
data:
  base_dataset:
    name: 'homogenous'
    num_signals_train: 500
    num_signals_val: 100
    num_signals_test: 100
    # Parameters for synthetic dataset
    size: 32
    vmin_train: 0.1
    vmax_train: 2.0
    vmin_test: 0.1
    vmax_test: 2.0
  
  # Coordinate dataloader config
  train_batch_size: 4
  test_batch_size: 4
  n_coords: 20480 # same as NES
  num_pairs: 5120 # n_coords/ (batch_size*4)
  x_min: [-1.0, -1.0]
  x_max: [1.0, 1.0]
  num_workers: 8
  pin_memory: True
  train_save_data: True
  train_force_recompute: True
  val_save_data: True
  val_force_recompute: True
  test_save_data: True
  test_force_recompute: True


# Training configuration
training:
  num_epochs: 1000
  model_checkpoint: True
  early_stopping: True
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0


# Testing configuration
test:
  val_every_n_epochs: 15
  test_train: False

# Optimization configuration
optimizer:
  name: adamw
  learning_rate_solver: 1e-4
  learning_rate_outer_dec: 0.0
  weight_decay: 0.0
  lr_scheduler: 
    activate: True
    type: 'cosine'
    freq: 10.0
    min_lambda: 1e-2
    interval: 'step'
    warmup_steps: 0.0

meta:
  inner_learning_rate_p: 1.0
  inner_learning_rate_a: 5.0
  learning_rate_meta_sgd: 1e-4
  noise_pos_inner_loop: 1e-3
  num_inner_steps: 3
  num_pairs: 10240


visualization:
  active: True
  max_num_visualized_rec: 5
  max_pairs_plot: 25


